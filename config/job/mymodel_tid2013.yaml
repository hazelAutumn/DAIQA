# @package _global_

defaults:
  - _self_
  - /dist: single_gpu
  - /optimizer: adamW
  - /scheduler: cosineAnnealingLR
  - /log: train
  - /load: scratch
#  - /loss: mymodel_v1_pretrain
#  - /model: mymodel_v1_2

#model
model:
  model_name: mymodel_v1_2
  basic_model_name: vit_base_patch16_224.augreg2_in21k_ft_in1k
  basic_model_pretrained: true
  hyper_vit:
    dropout_rate: 0.1
  vit_param:
    img_size: 224
    patch_size: 16
    embed_dim: 768
    depth: 7
    qkv_bias: true
    num_heads: 12
    num_classes: 1000
  learner_param:
    num_classes: 1
    num_distortions: 25 #24 for tid, 25 for kadid
    embed_dim: ${model.vit_param.embed_dim}
    feature_channels: [256, 512, 1024, 2048]
    cnn_feature_num: 4
    interaction_block_num: ${model.vit_param.depth}
    latent_dim: 64
    grid_size: 7
    cross_attn_num_heads: 4
  feature_model:
    name: resnet50
    load_timm_model: true
    out_indices: [1, 2, 3, 4]

# job general configs
project_name: mymodel_v1_2_1.0_0
name: minev1_tid2013_pretrain_split${split_index}
run_group: minev1_tid2013_pretrain_split
working_dir: runs/${run_group}/${name}
random_seed: 3407
train_test_num: 1
num_epoch: 10
split_index: 0

# training configs
train:
  patch_num: 10
  batch_size: 128
  num_workers: 10

# test configs
test:
  patch_num: 15
  batch_size: 512
  num_workers: 10

# data
data:
  name: tid2013_d
  root: data/tid2013
  meta_info_file: data/meta_info/meta_info_withdist_TID2013Dataset.csv
  train_test_split_file: data/train_split_info/tid2013withdist_82_seed3407.pkl
  divide_dataset_per_gpu: true
  data_num: 3000
  train_data_num: 2400
  test_data_num: 600
  image_size: 384
  patch_size: 224

# loss
loss:
  fn:
  - [plcc_loss, 0.5]
  - [cross_entropy, 0.5]

# v1 of using distortion label - pretrain on a synthetic dataset